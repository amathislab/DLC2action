{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to DLC2Action (mini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DLC2Action is a package for automatic behavior prediction. It offers implementation of SOTA models and keeps track of experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how it works, we will experiment on a relatively small [publically available](https://github.com/ETHZ-INS/DLCAnalyzer/tree/master/data/OFT) dataset (Sturman, 2020). Run the code below to download the data.\n",
    "\n",
    "This is a minimalistic version of this notebook, check out demo_notebook.ipynb for more information.\n",
    "\n",
    "Note that the results we are getting here are not optimal because we are using very small numbers of epochs and trials to make the execution time fit within a short tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown https://drive.google.com/uc?id=1c-dX7MtRGPSGSrNp3Uaf3aOIzokzuj69\n",
    "!apt-get install unzip\n",
    "!unzip OFT.zip -d OFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... installation\n",
    "\n",
    "for now:\n",
    "```\n",
    "git clone https://github.com/AlexEMG/DLC2Action\n",
    "cd DLC2Action\n",
    "conda create --name DLC2Action python=3.9\n",
    "conda activate DLC2Action\n",
    "python -m pip install .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlc2action.project import Project\n",
    "import os\n",
    "\n",
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_PATH = os.path.join(CURRENT_PATH, \"OFT\", \"OFT\", \"Output_DLC\")\n",
    "LABELS_PATH = os.path.join(CURRENT_PATH, \"OFT\", \"OFT\", \"Labels\")\n",
    "PROJECTS_PATH = os.path.join(CURRENT_PATH, \"DLC2Action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-level methods in DLC2Action are almost exclusively accessed through the `dlc2action.project.Project` class. A project instance should loosely correspond to a specific goal (e.g. generating automatic annotations for dataset A with input format X). You can use it to optimize hyperparameters, run experiments, analyze results and generate new data.\n",
    "\n",
    "**Best practices**\n",
    "- When you need to do something with a different data type or unrelated files, it's better to create a new project to keep the experiment history easy to understand.\n",
    "- Each project is associated with a folder on your computer that contains all settings, meta files and experiment outputs. Those folders are created in the folder at `projects_path`. It's generally a good idea to choose one and stick to it throughout projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a project\n",
    "\n",
    "Let's begin!\n",
    "\n",
    "We will create a project called `\"oft\"`, with `\"dlc_track\"` input and `\"csv\"` annotation format. \n",
    "\n",
    "You can run `Project.print_data_types()` and `Project.print_annotation_types()` to find out more about other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project.remove_project(\"oft\", projects_path=PROJECTS_PATH)\n",
    "project = Project(\n",
    "    \"oft\",\n",
    "    data_path=DATA_PATH,\n",
    "    annotation_path=LABELS_PATH,\n",
    "    projects_path=PROJECTS_PATH,\n",
    "    data_type=\"dlc_track\",\n",
    "    annotation_type=\"csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the project is created, it's time to configure the parameter settings. \n",
    "\n",
    "The first step is to check which essential parameters are missing with `project.list_blanks()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.list_blanks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can copy this code, fill in the blanks and run it. \n",
    "\n",
    "We will also set the number of epochs here. Normally the default should be fine but for the purpose of this tutorial we want to set it smaller so that our experiments can finish in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.update_parameters(\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"data_suffix\": \"DeepCut_resnet50_Blockcourse1May9shuffle1_1030000.csv\", # set; the data files should have the format of {video_id}{data_suffix}, e.g. video1_suffix.pickle, where video1 is the video is and _suffix.pickle is the suffix\n",
    "            \"canvas_shape\": [928, 576], # list; the size of the canvas where the pose was defined\n",
    "            \"annotation_suffix\": \".csv\", # str | set, optional the suffix or the set of suffices such that the annotation files are named {video_id}{annotation_suffix}, e.g, video1_suffix.pickle where video1 is the video id and _suffix.pickle is the suffix\n",
    "        },\n",
    "        \"general\": {\n",
    "            \"exclusive\": True, # bool; if true, single-label classification is used; otherwise multi-label\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"num_epochs\": 15,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're all set and can start training models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many hyperparameters in model training, like the number of layers in a model or loss coefficients. The default settings for those parameters should generate reasonable results on most datasets but in order to get the most out of our data we can run a hyperparameter search.\n",
    "\n",
    "The easiest way to find a good set of hyperparameters for your data is to run `project.run_default_hyperparameter_search()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run_default_hyperparameter_search(\n",
    "    \"test_search\",\n",
    "    num_epochs=10,\n",
    "    n_trials=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train models with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run_episode(\n",
    "    \"test_best\",\n",
    "    load_search=\"test_search\", # loading the search\n",
    "    force=True, # when force=True, if an episode with this name already exists it will be overwritten -> use with caution!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our best models, we can analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.plot_episodes(\n",
    "    [\"test_best\"],\n",
    "    metrics=[\"f1\"], # F1 score\n",
    "    title=\"Best model training curve\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check out more metrics now. See `project.help(\"metrics\")` to see other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.evaluate(\n",
    "    [\"test_best\"],\n",
    "    parameters_update={\n",
    "        \"general\": {\"metric_functions\": [\"segmental_f1\", \"mAP\", \"f1\"]},\n",
    "        \"metrics\": {\n",
    "            \"f1\": {\"average\": \"none\"}\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you find that you are happy with the results, you can use the model to generate predictions for new data. \n",
    "\n",
    "Predictions here are probabilities of each behavior being seen in each frame while suggestions are suggested intervals generated from those probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a prediction with one of our models and look at one of the resulting files. Note that you can use multiple models and average over their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run_prediction(\n",
    "    \"test_best_prediction\",\n",
    "    episode_names=[f\"test_best\"],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "# picking a random file from the prediction folder\n",
    "prediction_folder = project.prediction_path(\"test_best_prediction\")\n",
    "prediction_file = os.listdir(prediction_folder)[0]\n",
    "prediction_file = os.path.join(prediction_folder, prediction_file)\n",
    "\n",
    "with open(prediction_file, \"rb\") as f: # open the file\n",
    "    prediction = pickle.load(f)\n",
    "\n",
    "for key, value in prediction.items(): # explore the contents\n",
    "    if key not in [\"max_frames\", \"min_frames\", \"video_tag\", \"behaviors\"]:\n",
    "        print(f'{key}: {value.shape}')\n",
    "    \n",
    "behaviors_order = prediction[\"behaviors\"]\n",
    "\n",
    "start = 50\n",
    "end = 70\n",
    "action = \"Unsupported\"\n",
    "\n",
    "index = behaviors_order.index(action)\n",
    "\n",
    "print(f'The mean probability of {action} between frames {start} and {end} is {prediction[\"ind0\"][index, start: end].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove unnecessary data to clean the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.remove_saved_features()\n",
    "project.remove_extra_checkpoints()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DLC2Action')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f5f7675fb80040f0ca1448b5f0ffd03eab1e03daeb908de054f4ee2164beb96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
