{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to DLC2Action (mini)\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/amathislab/DLC2action/blob/master/examples/minimal_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DLC2Action is a package for automatic behavior prediction. It offers implementation of SOTA models and keeps track of experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how it works, we will experiment on a relatively small [publically available](https://github.com/ETHZ-INS/DLCAnalyzer/tree/master/data/OFT) dataset (Sturman, 2020). Run the code below to download the data.\n",
    "\n",
    "This is a minimalistic version of this notebook, check out demo_notebook.ipynb for more information.\n",
    "\n",
    "Note that the results we are getting here are not optimal because we are using very small numbers of epochs and trials to make the execution time fit within a short tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: If you want to run this in google colab, we recommend to use the notebook at [this link](https://colab.research.google.com/drive/1z7s7T4mf_z4WN7ag6XFNFtPCMLlWnuR0?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Installing Packages and Downloading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the data and installing the packages can take up to about 5-10 minutes.\n",
    "\n",
    "First, let's download the data. </br>\n",
    "*For Windows user*, you may need to install `wget` by downloading the .exe file [here](https://eternallybored.org/misc/wget/) (>1.10.0) and moving it to the System32 directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/ETHZ-INS/DLCAnalyzer/archive/refs/heads/master.zip\n",
    "!apt-get install unzip\n",
    "!unzip master.zip\n",
    "!mv DLCAnalyzer-master/data/OFT OFT_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's install `dlc2action`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlc2action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLC2Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the necessary packages and specify where our data is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dlc2action.project import Project\n",
    "\n",
    "CURRENT_PATH = os.getcwd()\n",
    "DATA_PATH = os.path.join(CURRENT_PATH, \"OFT_data\", \"Output_DLC\")\n",
    "LABELS_PATH = os.path.join(CURRENT_PATH, \"OFT_data\", \"Labels\")\n",
    "PROJECTS_PATH = os.path.join(CURRENT_PATH, \"DLC2Action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to parse the data to make it compatible with `dlc2action` (one annotation file per video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = f\"{LABELS_PATH}/AllLabDataOFT_final.csv\"\n",
    "\n",
    "# loading the annotations\n",
    "df_labels = pd.read_csv(annotations, sep=\";\")\n",
    "\n",
    "# Getting the video name from the dlc filename\n",
    "model = \"DeepCut_resnet50_Blockcourse1May9shuffle1_1030000.csv\"\n",
    "df_labels[\"video\"] = df_labels[\"DLCFile\"].map(lambda dlc_file: dlc_file.split(model)[0])\n",
    "\n",
    "# Splitting the data into one csv for each video\n",
    "videos = df_labels[\"video\"].unique()\n",
    "for video in videos:\n",
    "    df_video_labels = df_labels[df_labels[\"video\"] == video]\n",
    "    df_video_labels = df_video_labels.drop(\"video\", axis=1)\n",
    "    df_video_labels.to_csv(f\"{LABELS_PATH}/{video}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can move on to `DLC2Action`.\n",
    "\n",
    "High-level methods in DLC2Action are almost exclusively accessed through the `dlc2action.project.Project` class. A project instance should loosely correspond to a specific goal (e.g. generating automatic annotations for dataset A with input format X). You can use it to optimize hyperparameters, run experiments, analyze results and generate new data. On the other hand, if you want to test different models, different model parameters, augmentations or types of extracted features it is better to work in the same project instance to compare these experiments.\n",
    "\n",
    "**Best practices**\n",
    "- When you need to do something with a different data type or unrelated files, it's better to create a new project to keep the experiment history easy to understand.\n",
    "- Each project is associated with a folder on your computer that contains all settings, meta files and experiment outputs. Those folders are created in the folder at `projects_path`. It's generally a good idea to choose one and stick to it throughout projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a project\n",
    "\n",
    "Let's begin!\n",
    "\n",
    "We will create a project called `\"oft\"`, with `\"dlc_track\"` input and `\"csv\"` annotation format. \n",
    "\n",
    "You can run `Project.print_data_types()` and `Project.print_annotation_types()` to find out more about other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project.remove_project(\"oft\", projects_path=PROJECTS_PATH)\n",
    "project = Project(\n",
    "    \"oft\",\n",
    "    data_path=DATA_PATH,\n",
    "    annotation_path=LABELS_PATH,\n",
    "    projects_path=PROJECTS_PATH,\n",
    "    data_type=\"dlc_track\",\n",
    "    annotation_type=\"csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the project is created, it's time to configure the parameter settings. \n",
    "\n",
    "The first step is to check which essential parameters are missing with `project.list_blanks()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.list_blanks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can copy this code, fill in the blanks and run it. \n",
    "\n",
    "We will also set the classes we want to ignore and number of epochs here. Normally the default should be fine but for the purpose of this tutorial we want to set it smaller so that our experiments can finish in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.update_parameters(\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"data_suffix\": \"DeepCut_resnet50_Blockcourse1May9shuffle1_1030000.csv\", # set; the data files should have the format of {video_id}{data_suffix}, e.g. video1_suffix.pickle, where video1 is the video is and _suffix.pickle is the suffix\n",
    "            \"canvas_shape\": [928, 576], # list; the size of the canvas where the pose was defined\n",
    "            \"annotation_suffix\": \".csv\", # str | set, optional the suffix or the set of suffices such that the annotation files are named {video_id}{annotation_suffix}, e.g, video1_suffix.pickle where video1 is the video id and _suffix.pickle is the suffix\n",
    "            \"fps\": 25, # int; fps (assuming the annotations are given in seconds, otherwise set any value)\n",
    "            \"ignored_classes\": [\"StartEnd\", \"_DEFAULT\"]\n",
    "        },\n",
    "        \"general\": {\n",
    "            \"exclusive\": True, # bool; if true, single-label classification is used; otherwise multi-label\n",
    "        },\n",
    "        \"training\": {\n",
    "            \"num_epochs\": 15,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're all set and can start training models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many hyperparameters in model training, like the number of layers in a model or loss coefficients. The default settings for those parameters should generate reasonable results on most datasets but in order to get the most out of our data we can run a hyperparameter search. The default model is called C2F-TCN and is a temporal convolution neural network and can also be changed while updating the parameters.\n",
    "\n",
    "The easiest way to find a good set of hyperparameters for your data is to run `project.run_default_hyperparameter_search()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run_default_hyperparameter_search(\n",
    "    \"test_search\",\n",
    "    num_epochs=3,\n",
    "    n_trials=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a model with the best hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run_episode(\n",
    "    \"test_best\",\n",
    "    load_search=\"test_search\", # loading the search\n",
    "    force=True, # when force=True, if an episode with this name already exists it will be overwritten -> use with caution!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained our best models, we can analyze the results. In action segmentation tasks, the F1 score is given by the ratio of the product between precision and recall of a given class divided by their sum. Here we plot the evolution of F1 score during the model training. It can gives many indication on whether to stop the training or continue experimenting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.plot_episodes(\n",
    "    [\"test_best\"],\n",
    "    metrics=[\"f1\"], # F1 score\n",
    "    title=\"Best model training curve\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check out more metrics now. See `project.help(\"metrics\")` to see other options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.evaluate(\n",
    "    [\"test_best\"],\n",
    "    parameters_update={\n",
    "        \"general\": {\"metric_functions\": [\"segmental_f1\", \"mAP\", \"f1\"]},\n",
    "        \"metrics\": {\n",
    "            \"f1\": {\"average\": \"none\"}\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are happy with the results, you can use the model to generate predictions for new data.\n",
    "\n",
    "Predictions here are given by the probabilities of each behavior being seen in each frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a prediction using our trained model and look at one of the resulting files. Note that you can use multiple models and average over their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.run_prediction(\n",
    "    \"test_best_prediction\",\n",
    "    episode_names=[f\"test_best\"],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "# picking a random file from the prediction folder\n",
    "prediction_folder = project.prediction_path(\"test_best_prediction\")\n",
    "prediction_file = os.listdir(prediction_folder)[0]\n",
    "prediction_file = os.path.join(prediction_folder, prediction_file)\n",
    "\n",
    "with open(prediction_file, \"rb\") as f: # open the file\n",
    "    prediction = pickle.load(f)\n",
    "\n",
    "for key, value in prediction.items(): # explore the contents\n",
    "    if key not in [\"max_frames\", \"min_frames\", \"video_tag\", \"behaviors\"]:\n",
    "        print(f'{key}: {value.shape}')\n",
    "    \n",
    "behaviors_order = prediction[\"behaviors\"]\n",
    "\n",
    "start = 50\n",
    "end = 70\n",
    "action = \"Unsupported\"\n",
    "\n",
    "index = behaviors_order.index(action)\n",
    "\n",
    "print(f'The mean probability of {action} between frames {start} and {end} is {prediction[\"ind0\"][index, start: end].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove unnecessary data to clean the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.remove_saved_features()\n",
    "project.remove_extra_checkpoints()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('DLC2Action')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f5f7675fb80040f0ca1448b5f0ffd03eab1e03daeb908de054f4ee2164beb96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
